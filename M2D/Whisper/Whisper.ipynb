{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLuIKRGV1ACHQx4NdTJwbi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saultr21/IA-Y-BIGDATA/blob/main/M2D/Whisper/Whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalación de Librerías y Dependencias Básicas\n",
        "\n",
        "En este bloque se instalan todas las dependencias necesarias para el proyecto:\n",
        "\n",
        "- **Transformers:** Para utilizar modelos de Hugging Face.\n",
        "- **Torch:** Base de PyTorch para operaciones de deep learning.\n",
        "- **FFmpeg:** Para la manipulación y conversión de archivos de audio.\n",
        "- **Datasets:** Librería auxiliar para el manejo de datos.\n",
        "- **yt-dlp:** Para descargar y extraer audio (por ejemplo, de YouTube)."
      ],
      "metadata": {
        "id": "J7jsqpHQcLXy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikruG1kmVPiq"
      },
      "outputs": [],
      "source": [
        "# Instalamos las librerías necesarias\n",
        "!pip install transformers  # Para usar modelos de Hugging Face\n",
        "!pip install torch         # Librería base de PyTorch\n",
        "!apt-get install ffmpeg    # Para manipular y convertir archivos de audio\n",
        "!pip install datasets      # Librería auxiliar para manejo de datos\n",
        "!pip install yt-dlp\n",
        "!apt-get install ffmpeg -y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalación del Modelo Whisper de OpenAI\n",
        "\n",
        "En este bloque se instala la versión más reciente de **Whisper** directamente desde el repositorio oficial de GitHub de OpenAI. Esto garantiza que se cuente con la última versión disponible para la transcripción de audio.\n"
      ],
      "metadata": {
        "id": "Qd1zWg_EcOiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git  # Instala Whisper de OpenAI"
      ],
      "metadata": {
        "id": "WKMFGv-FW6cY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importación de Librerías\n",
        "\n",
        "En este bloque se importan los módulos necesarios para:\n",
        "\n",
        "- **whisper:** Cargar y utilizar el modelo de transcripción.\n",
        "- **os:** Interactuar con el sistema operativo (gestión de archivos, etc.).\n",
        "- **language_tool_python:** Posible uso en corrección gramatical o análisis del lenguaje.\n",
        "- **files (de google.colab):** Permitir la subida de archivos locales.\n"
      ],
      "metadata": {
        "id": "4831SboncPOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import os\n",
        "import language_tool_python\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "IwKip9FhYfFJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selección del Método de Carga del Audio\n",
        "\n",
        "Este bloque interactúa con el usuario para elegir cómo obtener el audio a transcribir. Se ofrecen dos opciones:\n",
        "\n",
        "1. **Subir un archivo local (WAV o MP3):**\n",
        "   - El usuario sube un archivo.\n",
        "   - Si el archivo es WAV, se convierte a MP3 usando FFmpeg.\n",
        "   - Si el archivo es MP3, se renombra a `audio.mp3`.\n",
        "\n",
        "2. **Descargar audio desde YouTube:**\n",
        "   - Se solicita la URL de un video de YouTube.\n",
        "   - Con *yt-dlp* se descarga y extrae el audio en formato MP3.\n",
        "   - Se renombra el archivo descargado a `audio.mp3`.\n",
        "\n",
        "Si el usuario ingresa una opción no válida, se muestra un mensaje de error.\n"
      ],
      "metadata": {
        "id": "AAs7cwG-cPyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# SELECCIÓN DE MÉTODO DE CARGA\n",
        "# =========================\n",
        "print(\"Seleccione la opción:\")\n",
        "print(\"1: Subir un archivo local (WAV o MP3)\")\n",
        "print(\"2: Descargar audio de YouTube\")\n",
        "option = input(\"Ingrese 1 o 2: \")\n",
        "\n",
        "if option.strip() == '1':\n",
        "    # -----------------------------------\n",
        "    # SUBIDA Y CONVERSIÓN DE ARCHIVO LOCAL\n",
        "    # -----------------------------------\n",
        "    print(\"Por favor, sube tu archivo de audio (WAV o MP3).\")\n",
        "    uploaded = files.upload()\n",
        "    # Se extrae el nombre del primer archivo subido\n",
        "    filename = list(uploaded.keys())[0]\n",
        "\n",
        "    if filename.lower().endswith('.wav'):\n",
        "        print(\"El archivo subido es WAV. Convirtiendo a MP3...\")\n",
        "        !ffmpeg -i \"{filename}\" -vn -ar 44100 -ac 2 -b:a 192k \"audio.mp3\"\n",
        "        print(\"Conversión completa. Archivo guardado como audio.mp3\")\n",
        "    elif filename.lower().endswith('.mp3'):\n",
        "        print(\"El archivo subido es MP3. No se requiere conversión.\")\n",
        "        !mv \"{filename}\" \"audio.mp3\"\n",
        "        print(\"Archivo renombrado a audio.mp3\")\n",
        "    else:\n",
        "        print(\"Formato no reconocido (no es WAV ni MP3). Se mantiene el nombre original.\")\n",
        "        print(f\"Archivo: {filename}\")\n",
        "\n",
        "elif option.strip() == '2':\n",
        "    # -----------------------------------\n",
        "    # DESCARGAR AUDIO DESDE YOUTUBE CON yt-dlp\n",
        "    # -----------------------------------\n",
        "    video_url = input(\"Ingresa la URL del video de YouTube: \")\n",
        "    output_name = \"audio.mp3\"\n",
        "\n",
        "    print(\"Descargando y convirtiendo audio desde YouTube...\")\n",
        "    # Se descarga y extrae el audio en formato MP3\n",
        "    !yt-dlp -x --audio-format mp3 -o \"{output_name}.%(ext)s\" {video_url}\n",
        "\n",
        "    # Aseguramos que el archivo final se llame 'audio.mp3'\n",
        "    !mv \"{output_name}.mp3\" \"audio.mp3\"\n",
        "\n",
        "    print(\"Descarga y conversión completadas. Archivo guardado como audio.mp3\")\n",
        "else:\n",
        "    print(\"Opción no válida. Por favor, reinicie el proceso y seleccione 1 o 2.\")\n"
      ],
      "metadata": {
        "id": "SVP0jI1HWHbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carga del Modelo y Transcripción del Audio\n",
        "\n",
        "En este bloque se realiza el procesamiento principal:\n",
        "\n",
        "1. **Carga del Modelo:**  \n",
        "   Se carga la versión \"base\" del modelo Whisper de OpenAI para la transcripción.\n",
        "\n",
        "2. **Transcripción:**  \n",
        "   Se utiliza el método `transcribe` para convertir el archivo `audio.mp3` en texto, mostrando información en tiempo real gracias al modo verbose.\n",
        "\n",
        "3. **Guardar Resultado:**  \n",
        "   La transcripción se guarda en un archivo llamado `transcripcion.txt` para su posterior consulta.\n"
      ],
      "metadata": {
        "id": "PmQPAmt-cQ0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga del modelo\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "# Transcripción con salida en tiempo real (modo verbose)\n",
        "result = model.transcribe(\"audio.mp3\", verbose=True)\n",
        "\n",
        "# Guardamos la transcripción final en un archivo .txt\n",
        "with open(\"transcripcion.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(result[\"text\"])"
      ],
      "metadata": {
        "id": "mjCjHTLUZ05J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}