{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMRhRyfR9GIO",
        "outputId": "0a9edf6e-e364-4e9f-f0b4-eb6eb5481186"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install textblob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "texto_1 = \"La película fue increíble.\"\n",
        "texto_2 = \"La comida aquí sabe horrible.\"\n",
        "texto_3 = \"El clima de hoy es agradable.\"\n",
        "texto_4 = \"Este libro es muy aburrido.\"\n",
        "texto_5 = \"La música en el concierto fue impresionante.\"\n",
        "\n",
        "# Determinando la Polaridad\n",
        "p_1 = TextBlob(texto_1).sentiment.polarity\n",
        "p_2 = TextBlob(texto_2).sentiment.polarity\n",
        "p_3 = TextBlob(texto_3).sentiment.polarity\n",
        "p_4 = TextBlob(texto_4).sentiment.polarity\n",
        "p_5 = TextBlob(texto_5).sentiment.polarity\n",
        "\n",
        "# Determinando la Subjetividad\n",
        "s_1 = TextBlob(texto_1).sentiment.subjectivity\n",
        "s_2 = TextBlob(texto_2).sentiment.subjectivity\n",
        "s_3 = TextBlob(texto_3).sentiment.subjectivity\n",
        "s_4 = TextBlob(texto_4).sentiment.subjectivity\n",
        "s_5 = TextBlob(texto_5).sentiment.subjectivity\n",
        "\n",
        "print(\"Polaridad de Texto 1:\", p_1)\n",
        "print(\"Polaridad de Texto 2:\", p_2)\n",
        "print(\"Polaridad de Texto 3:\", p_3)\n",
        "print(\"Polaridad de Texto 4:\", p_4)\n",
        "print(\"Polaridad de Texto 5:\", p_5)\n",
        "\n",
        "print(\"Subjetividad de Texto 1:\", s_1)\n",
        "print(\"Subjetividad de Texto 2:\", s_2)\n",
        "print(\"Subjetividad de Texto 3:\", s_3)\n",
        "print(\"Subjetividad de Texto 4:\", s_4)\n",
        "print(\"Subjetividad de Texto 5:\", s_5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLShlpAl9UYx",
        "outputId": "5afe6545-cc9b-4706-e0ca-8296ea8a7c38"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polaridad de Texto 1: 0.0\n",
            "Polaridad de Texto 2: -1.0\n",
            "Polaridad de Texto 3: 0.0\n",
            "Polaridad de Texto 4: 0.0\n",
            "Polaridad de Texto 5: 0.0\n",
            "Subjetividad de Texto 1: 0.0\n",
            "Subjetividad de Texto 2: 1.0\n",
            "Subjetividad de Texto 3: 0.0\n",
            "Subjetividad de Texto 4: 0.0\n",
            "Subjetividad de Texto 5: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0t2W4-F9bx1",
        "outputId": "ae04627a-cd72-4fa8-9aa6-173f5596fbe9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2024.8.30)\n",
            "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m122.9/126.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Inicializar el analizador de sentimientos\n",
        "sentimiento = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Frases para analizar\n",
        "texto_1 = \"El libro tenía un equilibrio perfecto entre estilo de escritura y trama.\"\n",
        "texto_2 = \"La pizza sabe horrible.\"\n",
        "texto_3 = \"La vista desde la montaña es impresionante.\"\n",
        "texto_4 = \"La atención al cliente en esta tienda es mala.\"\n",
        "texto_5 = \"Estoy muy contento con mi nueva computadora.\"\n",
        "\n",
        "# Análisis de sentimientos\n",
        "sent_1 = sentimiento.polarity_scores(texto_1)\n",
        "sent_2 = sentimiento.polarity_scores(texto_2)\n",
        "sent_3 = sentimiento.polarity_scores(texto_3)\n",
        "sent_4 = sentimiento.polarity_scores(texto_4)\n",
        "sent_5 = sentimiento.polarity_scores(texto_5)\n",
        "\n",
        "# Imprimir resultados\n",
        "print(\"Sentimiento de texto 1:\", sent_1)\n",
        "print(\"Sentimiento de texto 2:\", sent_2)\n",
        "print(\"Sentimiento de texto 3:\", sent_3)\n",
        "print(\"Sentimiento de texto 4:\", sent_4)\n",
        "print(\"Sentimiento de texto 5:\", sent_5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIW3U5Wj9gvE",
        "outputId": "e884cc45-6287-469e-86c8-0b01b4fcfe6d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentimiento de texto 1: {'neg': 0.0, 'neu': 0.827, 'pos': 0.173, 'compound': 0.3182}\n",
            "Sentimiento de texto 2: {'neg': 0.538, 'neu': 0.462, 'pos': 0.0, 'compound': -0.5423}\n",
            "Sentimiento de texto 3: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
            "Sentimiento de texto 4: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
            "Sentimiento de texto 5: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the Dataset\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "data = pd.read_csv('data.csv')\n",
        "#Pre-Prcoessing and Bag of Word Vectorization using Count Vectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
        "text_counts = cv.fit_transform(data['Sentence'])\n",
        "#Splitting the data into trainig and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, data['Sentiment'], test_size=0.25, random_state=5)\n",
        "#Training the model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "MNB = MultinomialNB()\n",
        "MNB.fit(X_train, Y_train)\n",
        "#Caluclating the accuracy score of the model\n",
        "from sklearn import metrics\n",
        "predicted = MNB.predict(X_test)\n",
        "accuracy_score = metrics.accuracy_score(predicted, Y_test)\n",
        "print(\"Accuracuy Score: \",accuracy_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12-RASrH-yW_",
        "outputId": "cad388d0-1c67-4bbd-92f3-d438e7f2e7d1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracuy Score:  0.6851471594798083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saul\n",
        "# Importar las bibliotecas necesarias\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from textblob import Word\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, LeakyReLU\n",
        "\n",
        "# Descargar recursos necesarios\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Cargar el conjunto de datos\n",
        "data = pd.read_csv('data.csv')\n",
        "\n",
        "# Preprocesamiento del texto\n",
        "def cleaning(df, stop_words):\n",
        "    df['Sentence'] = df['Sentence'].apply(lambda x: ' '.join(x.lower() for x in x.split()))\n",
        "    # Reemplazar los dígitos/números\n",
        "    df['Sentence'] = df['Sentence'].str.replace('d', '', regex=False)\n",
        "    # Eliminar palabras vacías\n",
        "    df['Sentence'] = df['Sentence'].apply(lambda x: ' '.join(x for x in x.split() if x not in stop_words))\n",
        "    # Lematización\n",
        "    df['Sentence'] = df['Sentence'].apply(lambda x: ' '.join([Word(x).lemmatize() for x in x.split()]))\n",
        "    return df\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "data_cleaned = cleaning(data, stop_words)\n",
        "\n",
        "# Generar embeddings usando Tokenizer\n",
        "tokenizer = Tokenizer(num_words=500, split=' ')\n",
        "tokenizer.fit_on_texts(data_cleaned['Sentence'].values)\n",
        "X = tokenizer.texts_to_sequences(data_cleaned['Sentence'].values)\n",
        "X = pad_sequences(X)\n",
        "\n",
        "# Codificar las etiquetas\n",
        "y = pd.get_dummies(data_cleaned['Sentiment']).values\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Construcción del modelo\n",
        "model = Sequential()\n",
        "model.add(Embedding(500, 120, input_length=X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(704, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(352))  # Capa densa sin activación\n",
        "model.add(LeakyReLU(alpha=0.1))  # Agregar LeakyReLU como una capa separada\n",
        "model.add(Dense(3, activation='softmax'))  # Capa de salida con softmax\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1)\n",
        "\n",
        "#Model Testing\n",
        "model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NPLf198tADWt",
        "outputId": "5c1b96e9-16c7-4834-87f6-5460365f8be9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ spatial_dropout1d_3                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ spatial_dropout1d_3                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/20\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 974ms/step - accuracy: 0.5355 - loss: 0.9823\n",
            "Epoch 2/20\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 988ms/step - accuracy: 0.6192 - loss: 0.8300\n",
            "Epoch 3/20\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 970ms/step - accuracy: 0.6897 - loss: 0.7288\n",
            "Epoch 4/20\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 980ms/step - accuracy: 0.6599 - loss: 0.7644\n",
            "Epoch 5/20\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 1s/step - accuracy: 0.6984 - loss: 0.6826\n",
            "Epoch 6/20\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 933ms/step - accuracy: 0.7169 - loss: 0.6281\n",
            "Epoch 7/20\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 943ms/step - accuracy: 0.7096 - loss: 0.6167\n",
            "Epoch 8/20\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 935ms/step - accuracy: 0.7326 - loss: 0.5752\n",
            "Epoch 9/20\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - accuracy: 0.7368 - loss: 0.5757\n",
            "Epoch 10/20\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 948ms/step - accuracy: 0.7420 - loss: 0.5505\n",
            "Epoch 11/20\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 951ms/step - accuracy: 0.7463 - loss: 0.5480\n",
            "Epoch 12/20\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 924ms/step - accuracy: 0.7421 - loss: 0.5290\n",
            "Epoch 13/20\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 951ms/step - accuracy: 0.7467 - loss: 0.5185\n",
            "Epoch 14/20\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 939ms/step - accuracy: 0.7470 - loss: 0.5054\n",
            "Epoch 15/20\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 935ms/step - accuracy: 0.7706 - loss: 0.4702\n",
            "Epoch 16/20\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 949ms/step - accuracy: 0.7746 - loss: 0.4739\n",
            "Epoch 17/20\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 940ms/step - accuracy: 0.7839 - loss: 0.4466\n",
            "Epoch 18/20\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 959ms/step - accuracy: 0.7841 - loss: 0.4724\n",
            "Epoch 19/20\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 927ms/step - accuracy: 0.7837 - loss: 0.4330\n",
            "Epoch 20/20\n",
            "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 926ms/step - accuracy: 0.7763 - loss: 0.4336\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 274ms/step - accuracy: 0.6528 - loss: 1.0183\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.011055827140808, 0.6544054746627808]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5XT3OFvmRkeF",
        "outputId": "391a3b38-3256-440a-e3a7-1ff7dc5ca041"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers"
      ],
      "metadata": {
        "id": "VRR3Sg50Rrim"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saul\n",
        "from transformers import pipeline\n",
        "\n",
        "# Crear el pipeline de análisis de sentimientos\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "\n",
        "# Lista ampliada de datos en español\n",
        "data = [\n",
        "    \"Fue el mejor de los tiempos.\",\n",
        "    \"Fue el peor de los tiempos.\",\n",
        "    \"¡Me encantó la nueva película!\",\n",
        "    \"El servicio en el restaurante fue terrible.\",\n",
        "    \"¡Me siento genial con los resultados de mi examen!\",\n",
        "    \"Este producto está bien, nada especial.\",\n",
        "    \"¡El clima hoy es fantástico!\",\n",
        "    \"Estoy realmente decepcionado con el servicio al cliente.\",\n",
        "    \"¡Qué maravillosa ha sido esta experiencia!\",\n",
        "    \"No estoy seguro si me gusta este plato.\",\n",
        "    \"Ha sido una semana estresante en el trabajo.\",\n",
        "    \"¡Disfruté cada momento de mis vacaciones!\",\n",
        "    \"El concierto fue una gran decepción.\",\n",
        "    \"¡No puedo esperar para ver a mis amigos de nuevo!\",\n",
        "    \"¡Este libro fue una lectura fascinante!\"\n",
        "]\n",
        "\n",
        "# Ejecutar el análisis de sentimientos\n",
        "results = sentiment_pipeline(data)\n",
        "\n",
        "for text, sentiment in zip(data, results):\n",
        "    print(f\"Texto: {text} | Sentimiento: {sentiment['label']}, Puntuación: {sentiment['score']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDqjOPH2SrG9",
        "outputId": "c5532183-c2fd-48e7-81dc-50a27553ee8a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto: Fue el mejor de los tiempos. | Sentimiento: 5 stars, Puntuación: 0.8662\n",
            "Texto: Fue el peor de los tiempos. | Sentimiento: 1 star, Puntuación: 0.5878\n",
            "Texto: ¡Me encantó la nueva película! | Sentimiento: 5 stars, Puntuación: 0.8727\n",
            "Texto: El servicio en el restaurante fue terrible. | Sentimiento: 1 star, Puntuación: 0.7307\n",
            "Texto: ¡Me siento genial con los resultados de mi examen! | Sentimiento: 5 stars, Puntuación: 0.8042\n",
            "Texto: Este producto está bien, nada especial. | Sentimiento: 3 stars, Puntuación: 0.5829\n",
            "Texto: ¡El clima hoy es fantástico! | Sentimiento: 5 stars, Puntuación: 0.8191\n",
            "Texto: Estoy realmente decepcionado con el servicio al cliente. | Sentimiento: 1 star, Puntuación: 0.6024\n",
            "Texto: ¡Qué maravillosa ha sido esta experiencia! | Sentimiento: 5 stars, Puntuación: 0.9266\n",
            "Texto: No estoy seguro si me gusta este plato. | Sentimiento: 3 stars, Puntuación: 0.3567\n",
            "Texto: Ha sido una semana estresante en el trabajo. | Sentimiento: 5 stars, Puntuación: 0.3371\n",
            "Texto: ¡Disfruté cada momento de mis vacaciones! | Sentimiento: 5 stars, Puntuación: 0.7168\n",
            "Texto: El concierto fue una gran decepción. | Sentimiento: 1 star, Puntuación: 0.6941\n",
            "Texto: ¡No puedo esperar para ver a mis amigos de nuevo! | Sentimiento: 5 stars, Puntuación: 0.6658\n",
            "Texto: ¡Este libro fue una lectura fascinante! | Sentimiento: 5 stars, Puntuación: 0.7250\n"
          ]
        }
      ]
    }
  ]
}